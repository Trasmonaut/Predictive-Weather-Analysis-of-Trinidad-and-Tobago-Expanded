{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f87ed22-59e7-4ce9-8c2c-83d644b44220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import calendar\n",
    "import string\n",
    "from string import punctuation\n",
    "from itertools import chain\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, f1_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation, TruncatedSVD\n",
    "from sklearn.feature_selection import SelectPercentile, chi2, f_regression, f_classif\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "df = pd.read_csv('Refined Datasets/Arima cleaned.csv', encoding='latin1')  #load Datafield csv\n",
    "df2 = pd.read_csv('Refined Datasets/Crown Point cleaned.csv', encoding='latin1')  #load Datafield csv\n",
    "df3 = pd.read_csv('Refined Datasets/Port of Spain cleaned.csv', encoding='latin1')  #load Datafield csv\n",
    "df4 = pd.read_csv('Refined Datasets/Rio Claro-Mayaro cleaned.csv', encoding='latin1')  #load Datafield csv\n",
    "df5 = pd.read_csv('Refined Datasets/San Fernando cleaned.csv', encoding='latin1')  #load Datafield csv\n",
    "df6 = pd.read_csv('Refined Datasets/Piarco cleaned.csv', encoding='latin1')  #load Datafield csv\n",
    "df7 = pd.read_csv('Refined Datasets/Diego Martin cleaned.csv', encoding='latin1')  #load Datafield csv\n",
    "df8 = pd.read_csv('Refined Datasets/Talparo cleaned.csv', encoding='latin1')  #load Datafield csv\n",
    "df9 = pd.read_csv('Refined Datasets/Chaguanas cleaned.csv', encoding='latin1')  #load Datafield csv\n",
    "df10 = pd.read_csv('Refined Datasets/Siparia cleaned.csv', encoding='latin1')  #load Datafield csv\n",
    "df11 = pd.read_csv('Refined Datasets/Sangre Grande cleaned.csv', encoding='latin1')  #load Datafield csv\n",
    "df12 = pd.read_csv('Refined Datasets/Princes Town cleaned.csv', encoding='latin1')  #load Datafield csv\n",
    "df13 = pd.read_csv('Refined Datasets/Scarborough cleaned.csv', encoding='latin1')  #load Datafield csv\n",
    "df14 = pd.read_csv('Refined Datasets/Penal-Debe cleaned.csv', encoding='latin1')  #load Datafield csv\n",
    "df15 = pd.read_csv('Refined Datasets/Point Fortin cleaned.csv', encoding='latin1')  #load Datafield csv\n",
    "df16 = pd.read_csv('Refined Datasets/San Juan-Laventille cleaned.csv', encoding='latin1')  #load Datafield csv\n",
    "\n",
    "pd.options.mode.copy_on_write = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0dc9aa3-0ada-45e6-90cd-0edd0eda4989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "stacked_df = pd.concat([df, df2, df3, df4, df5, df6,df7,df8,df9,df10,df11,df12,df13,df14,df15,df16])\n",
    "stacked_df.to_csv(\"Merged_DataSets.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afea2c7-e347-405e-bcab-77a663a04754",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
